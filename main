"""
neural network that fit given two dimentional vector to function 
"""

import numpy as np
import matplotlib.pyplot as plt

def sigmoid(x):
    return 1/(1+np.exp(-x))

def sigmoid_derivative(x):
    return x*(1-x)

def relu(x):
    return np.maximum(0,x)

def relu_derivative(x):
    return 1. * (x > 0)

def tanh(x):
    return np.tanh(x)

def tanh_derivative(x):
    return 1. - x**2

def softmax(x):
    e_x = np.exp(x - np.max(x))
    return e_x / e_x.sum()

def softmax_derivative(x):
    return x*(1-x)

def loss(y,y_hat):
    return -np.sum(y*np.log(y_hat))

def loss_derivative(y,y_hat):
    return -(y/y_hat)

def accuracy(y,y_hat):
    return np.sum(y==y_hat)/len(y)

class NeuralNetwork:
    def __init__(self,x,y,hidden_layers,activation_function,activation_derivative,loss_function,loss_derivative,learning_rate=0.01):
        self.input = x
        self.weights1 = np.random.rand(self.input.shape[1],hidden_layers)
        self.weights2 = np.random.rand(hidden_layers,1)
        self.y = y
        self.output = np.zeros(self.y.shape)
        self.activation_function = activation_function
        self.activation_derivative = activation_derivative
        self.loss_function = loss_function
        self.loss_derivative = loss_derivative
        self.learning_rate = learning_rate
        self.loss_list = []
        self.accuracy_list = []
        self.epoch_list = []
        self.epoch = 0
        self.accuracy = 0
        self.loss = 0
        self.accuracy_list.append(self.accuracy)
        self.loss_list.append(self.loss)
        self.epoch_list.append(self.epoch)

    def feedforward(self):
        self.layer1 = self.activation_function(np.dot(self.input,self.weights1))
        self.output = self.activation_function(np.dot(self.layer1,self.weights2))

    def backprop(self):
        d_weights2 = np.dot(self.layer1.T,(2*(self.y - self.output)*self.activation_derivative(self.output)))
        d_weights1 = np.dot(self.input.T,(np.dot(2*(self.y - self.output)*self.activation_derivative(self.output),self.weights2.T)*self.activation_derivative(self.layer1)))

        self.weights1 += self.learning_rate*d_weights1
        self.weights2 += self.learning_rate*d_weights2

    def train(self,epochs):
        for i in range(epochs):
            self.feedforward()
            self.backprop()
            self.epoch += 1
            self.loss = self.loss_function(self.y,self.output)
            self.loss_list.append(self.loss)
            self.epoch_list.append(self.epoch)
            self.accuracy = accuracy(self.y,self.output)
            self.accuracy_list.append(self.accuracy)
            print("epoch: ",self.epoch," loss: ",self.loss," accuracy: ",self.accuracy)

    def predict(self,x):
        self.layer1 = self.activation_function(np.dot(x,self.weights1))
        self.output = self.activation_function(np.dot(self.layer1,self.weights2))
        return self.output

    def plot_loss(self):
        plt.plot(self.epoch_list,self.loss_list)
        plt.xlabel("epoch")
        plt.ylabel("loss")
        plt.show()

    def plot_accuracy(self):
        plt.plot(self.epoch_list,self.accuracy_list)
        plt.xlabel("epoch")
        plt.ylabel("accuracy")
        plt.show()

if __name__ == "__main__":
    x = np.array([[0,0],[0,1],[1,0],[1,1]])
    y = np.array([[0],[1],[1],[0]])
    nn = NeuralNetwork(x,y,2,sigmoid,sigmoid_derivative,loss,loss_derivative)
    nn.train(10000)
    nn.plot_loss()
    nn.plot_accuracy()
